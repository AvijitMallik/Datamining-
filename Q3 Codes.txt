Q3: 

# Filtering by trim "350"
data350 <- sclass %>% group_by(trim) %>% filter(trim=="350")

#Split the data into a training and a testing set.
#Run K-nearest-neighbors, for many different values of K, starting at K=2 and going as high as you need to. For each value of K, fit the model to the training set and make predictions on your test set.

maxK=200

rmse_350 =   foreach(K = 2:maxK, .combine='rbind') %do% {

data350_split =  initial_split(data350, prop=0.8)
  data350_train = training(data350_split)
  data350_test  = testing(data350_split)

knn1 = knnreg(price ~ mileage, data=data350_train, k=K)
c(km=K,rmse=modelr::rmse(knn1,data=data350_test))
}%>% as.data.frame

#Calculate the out-of-sample root mean-squared error (RMSE) for each value of K.

view(rmse_350)

# make a plot of RMSE versus K, so that we can see where it bottoms out.

ggplot(rmse_350, aes(km))+geom_line(aes(y=rmse), color = "tomato")+ggtitle("RMSE/K of 350")+theme(plot.title = element_text(hjust = 0.5))

# Then for the optimal value of K, show a plot of the fitted model, i.e. predictions vs. x. 

knn70 = knnreg(price ~ mileage, data=data350, k=70)
data350_test = data350_test %>%
  mutate(price_pred1 = predict(knn70, data350_test))
p_test = ggplot(data = data350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
p_test + geom_line(aes(x = mileage, y = price_pred1), color='red', size=1.5)

***The optimal value of K changes as the data are randomly splited each time. 

# Filtering by trim "65 AMG"
dataAMG <- sclass %>% group_by(trim) %>% filter(trim=="65 AMG")

#Split the data into a training and a testing set.
#Run K-nearest-neighbors, for many different values of K, starting at K=2 and going as high as you need to. For each value of K, fit the model to the training set and make predictions on your test set.

maxK=200

rmse_AMG =   foreach(K = 2:maxK, .combine='rbind') %do% {
dataAMG_split =  initial_split(dataAMG, prop=0.8)
  dataAMG_train = training(dataAMG_split)
  dataAMG_test  = testing(dataAMG_split)
knn1 = knnreg(price ~ mileage, data=dataAMG_train, k=K)
c(km=K,rmse=modelr::rmse(knn1,data=dataAMG_test))
}%>% as.data.frame

#Calculate the out-of-sample root mean-squared error (RMSE) for each value of K.
view(rmse_AMG)

# make a plot of RMSE versus K, so that we can see where it bottoms out.

ggplot(rmse_AMG, aes(km))+geom_line(aes(y=rmse), color = "tomato")+ggtitle("RMSE/K of 65 AMG")+theme(plot.title = element_text(hjust = 0.5))

# Then for the optimal value of K, show a plot of the fitted model, i.e. predictions vs. x. 
knn31 = knnreg(price ~ mileage, data=dataAMG, k=31)
dataAMG_test = dataAMG_test %>%
  mutate(price_pred2 = predict(knn31, dataAMG_test))
p_test = ggplot(data = dataAMG_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
p_test + geom_line(aes(x = mileage, y = price_pred2), color='red', size=1.5)

***The optimal value of K changes as the data are randomly splited each time. 

## K-crossfold validation for trim 350.

data350_folds = crossv_kfold(data350, k=K_folds)
 models = map(data350_folds$train, ~ knnreg(price ~ mileage, k=100, data = ., use.all=FALSE))
 View(models)
 errs = map2_dbl(models, data350_folds$test, modelr::rmse)
 mean(errs)
 sd(errs)/sqrt(K_folds)

k_grid2 = c(2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,
36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,
71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,
106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,
136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167
168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200)
 cv_grid = foreach(k = k_grid, .combine='rbind') %dopar% {
    models = map(data350_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
     errs = map2_dbl(models, data350_folds$test, modelr::rmse)
    c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds))
 } %>% as.data.frame
 head(cv_grid)

 View(cv_grid)
 ggplot(cv_grid) + 
     geom_point(aes(x=k, y=err)) + 
   geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) + 
    scale_x_log10()

Optimal k=15
Fitted graph
knn15 = knnreg(price ~ mileage, data=data350, k=15)
data350_test = data350_test %>%
  mutate(price_pred1 = predict(knn15, data350_test))
p_test = ggplot(data = data350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
p_test + geom_line(aes(x = mileage, y = price_pred1), color='red', size=1.5)

dataAMG_folds = crossv_kfold(dataAMG, k=K_folds)
 models2 = map(dataAMG_folds$train, ~ knnreg(price ~ mileage, k=100, data = ., use.all=FALSE))
 View(models2)
errs2 = map2_dbl(models2, dataAMG_folds$test, modelr::rmse)

 mean(errs2)

 sd(errs2)/sqrt(K_folds)

 k_grid2 = c(2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,
36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,
71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,
106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,
136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167
168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200)

 cv_grid2 = foreach(k = k_grid2, .combine='rbind') %dopar% {
   models = map(dataAMG_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
    errs2 = map2_dbl(models, dataAMG_folds$test, modelr::rmse)
    c(k=k, err2 = mean(errs2), std_err2 = sd(errs2)/sqrt(K_folds))
 } %>% as.data.frame
head(cv_grid2)
cv_grid2%>% summarize(min_err=min(err))
 View(cv_grid2)
 ggplot(cv_grid2) + 
     geom_point(aes(x=k, y=err2)) + 
   geom_errorbar(aes(x=k, ymin = err2-std_err2, ymax = err2+std_err2)) + 
     scale_x_log10()

Optimal k=13
Fitted graph
knn13 = knnreg(price ~ mileage, data=dataAMG, k=13)
dataAMG_test = dataAMG_test %>%
  mutate(price_pred1 = predict(knn13, dataAMG_test))
p_test = ggplot(data = dataAMG_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
p_test + geom_line(aes(x = mileage, y = price_pred1), color='red', size=1.5)
